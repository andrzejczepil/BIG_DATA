{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc92979-b5a7-4c2c-8072-617de5474614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "train_data_df=pd.read_csv(\"trening.csv\", delimiter=\";\",header=None)\n",
    "train_data_df.columns=['Type', 'Text']\n",
    "TypeText=['pozytywny','negatywny','neutralny']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9183d0-e1fc-403b-9ea4-b031f06761eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df=pd.read_csv(\"test.csv\", delimiter=\";\",header=None)\n",
    "test_data_df.columns=['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17753c31-bb81-4885-99d4-68ca5deddce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jest super dzien i lubie nasze slonce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type                                   Text\n",
       "0     0  jest super dzien i lubie nasze slonce"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80768e8-2a00-4be9-a481-c14b20062f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zajecia/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zajecia/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mami'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "np.mean([len(s.split(\" \")) for s in train_data_df.Text])\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "POLISH_STOP_WORDS=['i','w','z','a','oraz','do','na','byc','sie','jest','mam','mamy','po']\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    # !!! zamien ponizsze swoja lista polskich stop words\n",
    "    stop_words=POLISH_STOP_WORDS,    \n",
    "    max_features = 85\n",
    ")\n",
    "\n",
    "corpus_data_features = vectorizer.fit_transform(\n",
    "    train_data_df.Text.tolist() + test_data_df.Text.tolist())\n",
    "corpus_data_features_nd = corpus_data_features.toarray()\n",
    "corpus_data_features_nd.shape\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "dist = np.sum(corpus_data_features_nd, axis=0)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        corpus_data_features_nd[0:len(train_data_df)], \n",
    "        train_data_df.Type,\n",
    "        train_size=0.85, \n",
    "        random_state=1234)\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=X_train, y=y_train)\n",
    "y_pred = log_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "760264f0-6b9b-4a35-83f7-dbbeeeb694e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.89      0.93      0.90         9\n",
      "weighted avg       0.93      0.89      0.89         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c81a7e1-e05f-4b45-8b9e-5b32d4b5c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2c5a6-e987-4721-9bf7-a8d8ae5583b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5daaabf-dba9-428d-8ddf-1622c9a25bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
